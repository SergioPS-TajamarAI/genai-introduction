{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "24086d9c",
   "metadata": {},
   "source": [
    "# Práctica: Eliminación Contextual de Stopwords para Análisis de Reseñas de Productos\n",
    "Este notebook implementa las fases descritas en el archivo `stop-words.md` para analizar y personalizar stopwords en reseñas de productos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "088bac57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                texto  \\\n",
      "El paquete llegó con el embalaje comprometido                aunque lograron reembolsarme rápidamente   \n",
      "Después de 3 semanas de espera                       el artículo nunca fue despachado. Pésimo segu...   \n",
      "La atención al cliente fue evasiva y poco resol...                                           negativo   \n",
      "Entrega express y producto en perfecto estado. ...                                           positivo   \n",
      "El sistema de seguimiento en línea mostró infor...                                           negativo   \n",
      "\n",
      "                                                                                               tokens  \n",
      "El paquete llegó con el embalaje comprometido                [ , lograron, reembolsarme, rápidamente]  \n",
      "Después de 3 semanas de espera                      [ , artículo, despachado, ., Pésimo, seguimiento]  \n",
      "La atención al cliente fue evasiva y poco resol...                                         [negativo]  \n",
      "Entrega express y producto en perfecto estado. ...                                         [positivo]  \n",
      "El sistema de seguimiento en línea mostró infor...                                         [negativo]  \n"
     ]
    }
   ],
   "source": [
    "# Fase 1: Análisis Inicial\n",
    "# Cargar el dataset y procesar texto con spaCy\n",
    "# %pip install spacy\n",
    "# !python -m spacy download es_core_news_sm\n",
    "\n",
    "import pandas as pd\n",
    "import spacy\n",
    "from spacy.lang.es.stop_words import STOP_WORDS\n",
    "\n",
    "# Cargar el dataset\n",
    "df = pd.read_csv('comentarios_clientes.csv')\n",
    "\n",
    "# Cargar modelo de spaCy\n",
    "nlp = spacy.load('es_core_news_sm')\n",
    "\n",
    "# Función para procesar texto\n",
    "def procesar_texto(texto):\n",
    "    doc = nlp(texto)\n",
    "    return [token.text for token in doc if not token.is_stop]\n",
    "\n",
    "# Aplicar procesamiento al dataset\n",
    "df['tokens'] = df['texto'].apply(procesar_texto)\n",
    "\n",
    "# Mostrar ejemplos\n",
    "print(df[['texto', 'tokens']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "46707342",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'acuerdo', 'adelante', 'ademas', 'además', 'afirmó', 'agregó', 'ahi', 'ahora', 'ahí', 'al', 'algo', 'alguna', 'algunas', 'alguno', 'algunos', 'algún', 'alli', 'allí', 'alrededor', 'ambos', 'ante', 'anterior', 'antes', 'apenas', 'aproximadamente', 'aquel', 'aquella', 'aquellas', 'aquello', 'aquellos', 'aqui', 'aquél', 'aquélla', 'aquéllas', 'aquéllos', 'aquí', 'arriba', 'aseguró', 'asi', 'así', 'atras', 'aun', 'añadió', 'aún', 'bajo', 'bastante', 'bien', 'breve', 'buen', 'buena', 'buenas', 'bueno', 'buenos', 'cada', 'casi', 'cierta', 'ciertas', 'cierto', 'ciertos', 'cinco', 'claro', 'cliente', 'comentó', 'como', 'con', 'conmigo', 'conocer', 'conseguimos', 'conseguir', 'considera', 'consideró', 'consigo', 'consigue', 'consiguen', 'consigues', 'contigo', 'contra', 'creo', 'cual', 'cuales', 'cualquier', 'cuando', 'cuanta', 'cuantas', 'cuanto', 'cuantos', 'cuatro', 'cuenta', 'cuál', 'cuáles', 'cuándo', 'cuánta', 'cuántas', 'cuánto', 'cuántos', 'cómo', 'da', 'dado', 'dan', 'dar', 'de', 'debajo', 'debe', 'deben', 'debido', 'decir', 'dejó', 'del', 'delante', 'demasiado', 'demás', 'dentro', 'deprisa', 'desde', 'despacio', 'despues', 'después', 'detras', 'detrás', 'dia', 'dias', 'dice', 'dicen', 'dicho', 'dieron', 'diez', 'diferente', 'diferentes', 'dijeron', 'dijo', 'dio', 'doce', 'donde', 'dos', 'durante', 'día', 'días', 'dónde', 'e', 'el', 'ella', 'ellas', 'ello', 'ellos', 'embargo', 'en', 'encima', 'encuentra', 'enfrente', 'enseguida', 'entonces', 'entre', 'era', 'eramos', 'eran', 'eras', 'eres', 'es', 'esa', 'esas', 'ese', 'eso', 'esos', 'esta', 'estaba', 'estaban', 'estado', 'estados', 'estais', 'estamos', 'estan', 'estar', 'estará', 'estas', 'este', 'esto', 'estos', 'estoy', 'estuvo', 'está', 'están', 'excepto', 'existe', 'existen', 'explicó', 'expresó', 'fin', 'final', 'fue', 'fuera', 'fueron', 'fui', 'fuimos', 'gracias', 'gran', 'grande', 'grandes', 'ha', 'haber', 'habia', 'habla', 'hablan', 'habrá', 'había', 'habían', 'hace', 'haceis', 'hacemos', 'hacen', 'hacer', 'hacerlo', 'haces', 'hacia', 'haciendo', 'hago', 'han', 'hasta', 'hay', 'haya', 'he', 'hecho', 'hemos', 'hicieron', 'hizo', 'hola', 'hoy', 'hubo', 'igual', 'incluso', 'indicó', 'informo', 'informó', 'ir', 'junto', 'la', 'lado', 'largo', 'las', 'le', 'les', 'llegó', 'lleva', 'llevar', 'lo', 'los', 'luego', 'mal', 'manera', 'manifestó', 'mas', 'mayor', 'me', 'mediante', 'medio', 'mejor', 'mencionó', 'menos', 'menudo', 'mi', 'mia', 'mias', 'mientras', 'mio', 'mios', 'mis', 'misma', 'mismas', 'mismo', 'mismos', 'modo', 'mucha', 'muchas', 'mucho', 'muchos', 'muy', 'más', 'mí', 'mía', 'mías', 'mío', 'míos', 'nada', 'nadie', 'ni', 'ninguna', 'ningunas', 'ninguno', 'ningunos', 'ningún', 'nos', 'nosotras', 'nosotros', 'nuestra', 'nuestras', 'nuestro', 'nuestros', 'nueva', 'nuevas', 'nueve', 'nuevo', 'nuevos', 'o', 'ocho', 'once', 'os', 'otra', 'otras', 'otro', 'otros', 'para', 'parece', 'parte', 'partir', 'pasada', 'pasado', 'paìs', 'pd', 'peor', 'pesar', 'poca', 'pocas', 'poco', 'pocos', 'podeis', 'podemos', 'poder', 'podria', 'podriais', 'podriamos', 'podrian', 'podrias', 'podrá', 'podrán', 'podría', 'podrían', 'poner', 'por', 'porque', 'posible', 'primer', 'primera', 'primero', 'primeros', 'producto', 'pronto', 'propia', 'propias', 'propio', 'propios', 'proximo', 'próximo', 'próximos', 'pudo', 'pueda', 'puede', 'pueden', 'puedo', 'pues', 'qeu', 'que', 'quedó', 'queremos', 'quien', 'quienes', 'quiere', 'quiza', 'quizas', 'quizá', 'quizás', 'quién', 'quiénes', 'qué', 'realizado', 'realizar', 'realizó', 'repente', 'respecto', 'sabe', 'sabeis', 'sabemos', 'saben', 'saber', 'sabes', 'salvo', 'se', 'sea', 'sean', 'segun', 'segunda', 'segundo', 'según', 'seis', 'ser', 'sera', 'será', 'serán', 'sería', 'señaló', 'si', 'sido', 'siempre', 'siendo', 'siete', 'sigue', 'siguiente', 'sin', 'sino', 'sobre', 'sois', 'sola', 'solamente', 'solas', 'solo', 'solos', 'somos', 'son', 'soy', 'su', 'supuesto', 'sus', 'suya', 'suyas', 'suyo', 'suyos', 'sé', 'sí', 'sólo', 'tal', 'tambien', 'también', 'tan', 'tanto', 'tarde', 'te', 'temprano', 'tendrá', 'tendrán', 'teneis', 'tenemos', 'tener', 'tenga', 'tengo', 'tenido', 'tenía', 'tercera', 'tercero', 'ti', 'tiene', 'tienen', 'toda', 'todas', 'todavia', 'todavía', 'todo', 'todos', 'total', 'tras', 'trata', 'través', 'tres', 'tu', 'tus', 'tuvo', 'tuya', 'tuyas', 'tuyo', 'tuyos', 'tú', 'u', 'ultimo', 'un', 'una', 'unas', 'uno', 'unos', 'usa', 'usais', 'usamos', 'usan', 'usar', 'usas', 'uso', 'usted', 'ustedes', 'va', 'vais', 'vamos', 'van', 'varias', 'varios', 'vaya', 'veces', 'ver', 'verdad', 'verdadera', 'verdadero', 'vez', 'vosotras', 'vosotros', 'voy', 'vuestra', 'vuestras', 'vuestro', 'vuestros', 'y', 'ya', 'yo', 'él', 'ésa', 'ésas', 'ése', 'ésos', 'ésta', 'éstas', 'éste', 'éstos', 'última', 'últimas', 'último', 'últimos']\n"
     ]
    }
   ],
   "source": [
    "# Fase 2: Personalización de la Lista\n",
    "# Modificar la lista de stopwords\n",
    "from collections import Counter\n",
    "\n",
    "# Identificar palabras más frecuentes\n",
    "todas_palabras = [palabra for tokens in df['tokens'] for palabra in tokens]\n",
    "frecuencias = Counter(todas_palabras)\n",
    "\n",
    "# Preservar términos clave\n",
    "terminos_clave = {'no', 'nunca', 'tampoco', 'pero', 'aunque', 'sin embargo'}\n",
    "\n",
    "# Eliminar términos genéricos\n",
    "terminos_genericos = {'producto', 'cliente', 'día', 'hacer', 'tener', 'decir'}\n",
    "\n",
    "# Añadir stopwords específicas\n",
    "stopwords_es = STOP_WORDS.copy()\n",
    "stopwords_es.update({'hola', 'gracias', 'pd'})\n",
    "stopwords_es.difference_update(terminos_clave)\n",
    "stopwords_es.update(terminos_genericos)\n",
    "\n",
    "# Mostrar lista personalizada\n",
    "print(sorted(stopwords_es))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "77e6a3b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrada: No funciona bien, pero el diseño es bonito.\n",
      "Salida: ['No', 'funciona', ',', 'pero', 'diseño', 'bonito', '.']\n",
      "--------------------------------------------------\n",
      "Entrada: Nunca compré algo tan malo. Aunque el precio es bajo, no lo vale.\n",
      "Salida: ['Nunca', 'compré', 'malo', '.', 'Aunque', 'precio', ',', 'no', 'vale', '.']\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Fase 3: Implementación y Pruebas\n",
    "# Función para procesar texto con lista personalizada\n",
    "def procesar_texto_personalizado(texto):\n",
    "    doc = nlp(texto)\n",
    "    return [token.text for token in doc if token.text.lower() not in stopwords_es]\n",
    "\n",
    "# Casos de prueba\n",
    "casos_prueba = [\n",
    "    'No funciona bien, pero el diseño es bonito.',\n",
    "    'Nunca compré algo tan malo. Aunque el precio es bajo, no lo vale.'\n",
    "    ]\n",
    "\n",
    "# Probar casos\n",
    "for caso in casos_prueba:\n",
    "    print(f'Entrada: {caso}')\n",
    "    print(f'Salida: {procesar_texto_personalizado(caso)}')\n",
    "    print('-' * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f962e610",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filas con etiquetas válidas: 2\n",
      "Distribución de clases: {'neutral': 1, 'negativo': 1}\n",
      "Exactitud sin stopwords personalizadas: 1.0\n",
      "Exactitud con stopwords personalizadas: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Fase 4: Evaluación de Impacto\n",
    "# Comparar análisis de sentimiento con y sin stopwords personalizadas\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Filtrar filas con valores NaN en 'etiqueta'\n",
    "df_clean = df.dropna(subset=['etiqueta'])\n",
    "\n",
    "# Verificar que tenemos datos después del filtrado\n",
    "print(f'Filas con etiquetas válidas: {len(df_clean)}')\n",
    "\n",
    "# Vectorizar texto\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(df_clean['texto'])\n",
    "y = df_clean['etiqueta']\n",
    "\n",
    "# Con solo 2 muestras etiquetadas, usamos todo el conjunto para demostración\n",
    "# En un caso real con más datos, usaríamos stratify=y para mantener la distribución de clases\n",
    "print(f\"Distribución de clases: {y.value_counts().to_dict()}\")\n",
    "\n",
    "# Entrenar modelo básico con todas las muestras\n",
    "modelo = LogisticRegression(max_iter=1000)\n",
    "modelo.fit(X, y)\n",
    "\n",
    "# Evaluar en el mismo conjunto (solo para demostración)\n",
    "y_pred = modelo.predict(X)\n",
    "print(f'Exactitud sin stopwords personalizadas: {accuracy_score(y, y_pred)}')\n",
    "\n",
    "# Vectorizar con stopwords personalizadas\n",
    "vectorizer_personalizado = CountVectorizer(stop_words=list(stopwords_es))\n",
    "X_personalizado = vectorizer_personalizado.fit_transform(df_clean['texto'])\n",
    "\n",
    "# Entrenar modelo con stopwords personalizadas\n",
    "modelo_p = LogisticRegression(max_iter=1000)\n",
    "modelo_p.fit(X_personalizado, y)\n",
    "y_pred_p = modelo_p.predict(X_personalizado)\n",
    "print(f'Exactitud con stopwords personalizadas: {accuracy_score(y, y_pred_p)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
